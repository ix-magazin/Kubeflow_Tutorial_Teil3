{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "\n",
    "Classify the musical genre of a given audio track - from data to deployed model. Adapted from the work of Huang, Serafini, and Pugh [1].\n",
    "\n",
    "## Authors\n",
    "- Sebastian Lehrig <sebastian.lehrig1@ibm.com>\n",
    "- Marvin Giessing <MARVING@de.ibm.com>\n",
    "\n",
    "## License\n",
    "Apache-2.0 License\n",
    "\n",
    "## References\n",
    "[1] original paper: http://cs229.stanford.edu/proj2018/report/21.pdf\n",
    "\n",
    "[2] code: https://github.com/derekahuang/Music-Classification\n",
    "\n",
    "[3] Preprocessed Data: https://drive.google.com/file/d/12mCgkvbmissLh2Vop0bp_t98G8QCaV1E/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.) Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "import json\n",
    "import kfp\n",
    "from kfp.components import (\n",
    "    InputPath,\n",
    "    OutputPath\n",
    ")\n",
    "import kfp.dsl as dsl\n",
    "from kfp.dsl import (\n",
    "    PipelineConf,\n",
    "    data_passing_methods\n",
    ")\n",
    "from kubernetes.client.models import (\n",
    "    V1Volume,\n",
    "    V1PersistentVolumeClaimVolumeSource\n",
    ")\n",
    "import librosa as lb\n",
    "from librosa import display\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab\n",
    "import requests\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-specific configurations\n",
    "#\n",
    "# %env MINIO_URL minio-service-kubeflow.apps.b2s001.pbm.ihost.com\n",
    "# %env REMOTE_HOST https://129.40.19.51:6443\n",
    "# %env REMOTE_HOST https://129.40.19.55:6443\n",
    "# %env REMOTE_NAMESPACE kubeadmin-cluster-local\n",
    "# %env REMOTE_NAMESPACE default\n",
    "# %env TRAINING_GPUS 1\n",
    "# %env TRAINING_NODE_SELECTOR nvidia.com/gpu.product: \"Tesla-V100-SXM2-32GB\"\n",
    "# %env TRAINING_NODE_SELECTOR kubernetes.io/hostname: node2\n",
    "#\n",
    "# Reset:\n",
    "# del os.environ['MINIO_URL']\n",
    "# del os.environ['REMOTE_HOST']\n",
    "# del os.environ['REMOTE_NAMESPACE']\n",
    "# del os.environ['TRAINING_GPUS']\n",
    "# del os.environ['TRAINING_NODE_SELECTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blackboard': 'artefacts',\n",
       " 'dataset_url': 'Lehrig/GTZAN-Collection',\n",
       " 'dataset_configuration': 'mel_spectrograms',\n",
       " 'dataset_label_column': 'genre',\n",
       " 'model_name': 'music-classification',\n",
       " 'minio_url': 'minio-service-kubeflow.apps.b2s001.pbm.ihost.com',\n",
       " 'training_gpus': '1',\n",
       " 'training_node_selector': '',\n",
       " 'remote_host': 'https://129.40.19.55:6443',\n",
       " 'remote_namespace': 'default'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMPONENT_CATALOG_FOLDER = f\"{os.getenv('HOME')}/components\"\n",
    "COMPONENT_CATALOG_GIT = \"https://github.com/lehrig/kubeflow-ppc64le-components.git\"\n",
    "COMPONENT_CATALOG_RELEASE = \"main\"\n",
    "\n",
    "LOAD_DATASET_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/data-collection/load-dataset/component.yaml\"\n",
    "TRAIN_MODEL_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/model-building/train-model-job/component.yaml\"\n",
    "PLOT_CONFUSION_MATRIX_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/model-building/plot-confusion-matrix/component.yaml\"\n",
    "CONVERT_MODEL_TO_ONNX_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/model-building/convert-to-onnx/component.yaml\"\n",
    "UPLOAD_MODEL_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/model-building/upload-model/component.yaml\"\n",
    "DEPLOY_MODEL_WITH_KSERVE_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/model-deployment/deploy-model-with-kserve/component.yaml\"\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ibm/kubeflow-notebook-image-ppc64le:latest\"\n",
    "\n",
    "ARGUMENTS = {\n",
    "    'blackboard': 'artefacts',\n",
    "    'dataset_url': 'Lehrig/GTZAN-Collection',\n",
    "    'dataset_configuration': 'mel_spectrograms',\n",
    "    'dataset_label_column': 'genre',\n",
    "    'model_name': \"music-classification\",\n",
    "    'minio_url': os.getenv('MINIO_URL', default='minio-service.kubeflow:9000'),\n",
    "    'training_gpus': os.getenv('TRAINING_GPUS', default='1'),\n",
    "    'training_node_selector': os.getenv('TRAINING_NODE_SELECTOR', default=''),\n",
    "    'remote_host': os.getenv('REMOTE_HOST', default=''),\n",
    "    'remote_namespace': os.getenv('REMOTE_NAMESPACE', default=''),\n",
    "}\n",
    "MODEL_NAME = ARGUMENTS[\"model_name\"]\n",
    "\n",
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\") as f:\n",
    "    NAMESPACE = f.read()\n",
    "\n",
    "ARGUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Let's start with creating a client object for interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) The main part consists of defining the end-to-end workflow functions and create components from them\n",
    "### 2.0) Load component catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/home/jovyan/components' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone --branch $COMPONENT_CATALOG_RELEASE $COMPONENT_CATALOG_GIT $COMPONENT_CATALOG_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Load dataset (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset_comp = kfp.components.load_component_from_file(\n",
    "    LOAD_DATASET_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Preprocess data (one hot encoding etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(\n",
    "    dataset_dir: InputPath(str),\n",
    "    prep_dataset_dir: OutputPath(str),\n",
    "    batch_size: int = 200,\n",
    "):\n",
    "    \"\"\"Split data into train/dev/test data. Saves result into `prep_dataset_dir`.\"\"\"\n",
    "\n",
    "    from datasets import load_from_disk\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    print(f'Loading input dataset from {dataset_dir}...')\n",
    "    dataset = load_from_disk(dataset_dir)\n",
    "\n",
    "    # Preprocess\n",
    "    num_classes = dataset[\"train\"].features[\"genre\"].num_classes\n",
    "    one_hot_matrix = np.eye(num_classes)\n",
    "\n",
    "    def process(examples):\n",
    "        examples[\"genre\"] = [\n",
    "            one_hot_matrix[genre] for genre in examples[\"genre\"]\n",
    "        ]\n",
    "        return examples\n",
    "\n",
    "    prep_dataset = dataset.map(\n",
    "        process,\n",
    "        batched=True,\n",
    "        batch_size=batch_size,\n",
    "        num_proc=2,\n",
    "        keep_in_memory=True\n",
    "    )\n",
    "\n",
    "    prep_dataset = prep_dataset.with_format(\"numpy\")\n",
    "\n",
    "    print(f\"Saving pre-processed dataset to '{prep_dataset_dir}'...\")\n",
    "    if not os.path.exists(prep_dataset_dir):\n",
    "        os.makedirs(prep_dataset_dir)\n",
    "    prep_dataset.save_to_disk(prep_dataset_dir)\n",
    "    print(f\"Pre-processed Dataset saved. Contents of '{dataset_dir}':\")\n",
    "    print(os.listdir(dataset_dir))\n",
    "\n",
    "    print('Finished.')\n",
    "\n",
    "\n",
    "preprocess_dataset_comp = kfp.components.create_component_from_func(\n",
    "    func=preprocess_dataset,\n",
    "    base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    prep_dataset_dir: InputPath(str),\n",
    "    model_dir: OutputPath(str),\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 200\n",
    "):\n",
    "    \"\"\"Trains CNN model. Once trained, the model is persisted to `model_dir`.\"\"\"\n",
    "\n",
    "    from datasets import load_from_disk\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import (\n",
    "        BatchNormalization,\n",
    "        Conv2D,\n",
    "        Dense,\n",
    "        Dropout,\n",
    "        Flatten,\n",
    "        MaxPooling2D\n",
    "    )\n",
    "    from tensorflow.keras import regularizers\n",
    "    import time\n",
    "    from transformers import DefaultDataCollator\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Feature Learning Layers\n",
    "    model.add(Conv2D(64,\n",
    "                     kernel_size=(4, 4),\n",
    "                     activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(0.04),\n",
    "                     input_shape=(64, 173, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 4)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 5), activation='relu', kernel_regularizer=regularizers.l2(0.04)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (2, 2), activation='relu', kernel_regularizer=regularizers.l2(0.04)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Classification Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.04)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.04)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                  metrics=[tf.keras.metrics.categorical_accuracy])\n",
    "    print(model.summary())\n",
    "\n",
    "    dataset = load_from_disk(prep_dataset_dir)\n",
    "\n",
    "    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "    train_dataset = dataset[\"train\"].to_tf_dataset(\n",
    "        columns=['mel_spectrogram'],\n",
    "        label_cols=['genre'],\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    validation_dataset = dataset[\"validation\"].to_tf_dataset(\n",
    "        columns=['mel_spectrogram'],\n",
    "        label_cols=['genre'],\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    # see: https://github.com/huggingface/datasets/issues/4478\n",
    "    tf.data.experimental.save(train_dataset, \"./train\")\n",
    "    tf.data.experimental.save(validation_dataset, \"./val\")\n",
    "    train_dataset = tf.data.experimental.load(\"./train\")\n",
    "    validation_dataset = tf.data.experimental.load(\"./val\")\n",
    "\n",
    "    start = time.time()\n",
    "    hist = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=epochs)\n",
    "    print(\"\\n\\nTraining took \", time.time()-start, \"seconds\")\n",
    "\n",
    "    print(\"Model train history:\")\n",
    "    print(hist.history)\n",
    "\n",
    "    print(f\"Saving model to: {model_dir}\")\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model.save(model_dir)\n",
    "    print(f\"Model saved to: {model_dir}\")\n",
    "\n",
    "    print('Finished.')\n",
    "\n",
    "\n",
    "train_specification = kfp.components.func_to_component_text(\n",
    "    func=train_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_comp = kfp.components.load_component_from_file(\n",
    "    TRAIN_MODEL_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Evaluate model with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    prep_dataset_dir: InputPath(str),\n",
    "    model_dir: InputPath(str),\n",
    "    batch_size: int = 20\n",
    ") -> NamedTuple(\n",
    "        \"EvaluationOutput\", [\n",
    "            (\"mlpipeline_metrics\", \"Metrics\")\n",
    "        ]):\n",
    "    \"\"\"Loads a saved model from file and uses a pre-downloaded dataset for evaluation.\n",
    "    Model metrics are persisted to `{metrics_path}` for Kubeflow Pipelines metadata.\"\"\"\n",
    "\n",
    "    from collections import namedtuple\n",
    "    from datasets import load_from_disk\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    from transformers import DefaultDataCollator\n",
    "\n",
    "    dataset = load_from_disk(prep_dataset_dir)\n",
    "    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "    test_dataset = dataset[\"test\"].to_tf_dataset(\n",
    "        columns=['mel_spectrogram'],\n",
    "        label_cols=['genre'],\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "    # see: https://github.com/huggingface/datasets/issues/4478\n",
    "    tf.data.experimental.save(test_dataset, \"./test\")\n",
    "    test_dataset = tf.data.experimental.load(\"./test\")\n",
    "\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    (loss, accuracy) = model.evaluate(test_dataset)\n",
    "\n",
    "    print((loss, accuracy))\n",
    "\n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\n",
    "                \"name\": \"loss\",\n",
    "                \"numberValue\": str(loss),\n",
    "                \"format\": \"PERCENTAGE\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"accuracy\",\n",
    "                \"numberValue\": str(accuracy),\n",
    "                \"format\": \"PERCENTAGE\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "\n",
    "    return out_tuple(json.dumps(metrics))\n",
    "\n",
    "\n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    func=evaluate_model,\n",
    "    base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Create confusion matrix (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_comp = kfp.components.load_component_from_file(\n",
    "    PLOT_CONFUSION_MATRIX_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6) Convert model to ONNX (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_model_to_onnx_comp = kfp.components.load_component_from_file(\n",
    "    CONVERT_MODEL_TO_ONNX_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7) Upload model to MinIO artifact store (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_model_comp = kfp.components.load_component_from_file(\n",
    "    UPLOAD_MODEL_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8) Deploy the model using KServe (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_model_with_kserve_comp = kfp.components.load_component_from_file(\n",
    "    DEPLOY_MODEL_WITH_KSERVE_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Create the actual pipeline by combining the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "  name='Music Genre Classification',\n",
    "  description='An example pipeline that performs a music genre classification on audio data'\n",
    ")\n",
    "def music_genre_classification_pipeline(\n",
    "            blackboard: str,\n",
    "            dataset_url: str,\n",
    "            dataset_configuration: str,\n",
    "            dataset_label_column: str,\n",
    "            model_name: str,\n",
    "            minio_url: str,\n",
    "            training_gpus: int,\n",
    "            training_node_selector: str,\n",
    "            remote_host: str,\n",
    "            remote_namespace: str):\n",
    "    create_blackboard = dsl.VolumeOp(\n",
    "        name='Create Artefacts Blackboard',\n",
    "        resource_name=blackboard,\n",
    "        modes=dsl.VOLUME_MODE_RWO,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True\n",
    "    )\n",
    "\n",
    "    load_dataset_task = load_dataset_comp(\n",
    "        path=dataset_url,\n",
    "        configuration=dataset_configuration,\n",
    "        label_column=dataset_label_column\n",
    "    )\n",
    "    load_dataset_task.after(create_blackboard)\n",
    "\n",
    "    preprocess_dataset_task = preprocess_dataset_comp(\n",
    "        dataset_dir=load_dataset_task.outputs['dataset_dir'],\n",
    "    )\n",
    "\n",
    "    # InputPath and OutputPath like \"prep_dataset_dir\" & \"model_dir\":\n",
    "    # Use name of parameters of train component on right-hand side.\n",
    "    train_parameters = {\n",
    "        \"prep_dataset_dir\": \"dataset_directory\",\n",
    "        \"model_dir\": \"model_dir\",\n",
    "        \"epochs\": \"2\",\n",
    "    }\n",
    "\n",
    "    train_model_task = train_model_comp(\n",
    "            preprocess_dataset_task.outputs['prep_dataset_dir'],\n",
    "            train_specification,\n",
    "            train_parameters,\n",
    "            model_name=model_name,\n",
    "            gpus=training_gpus,\n",
    "            node_selector=training_node_selector,\n",
    "            remote_host=remote_host,\n",
    "            namespace=remote_namespace,\n",
    "            minio_url=minio_url,\n",
    "        )\n",
    "\n",
    "    evaluate_model_comp(\n",
    "        preprocess_dataset_task.outputs['prep_dataset_dir'],\n",
    "        train_model_task.outputs['model_dir']\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix_comp(\n",
    "        \"mel_spectrogram\",\n",
    "        \"genre\",\n",
    "        preprocess_dataset_task.outputs['prep_dataset_dir'],\n",
    "        train_model_task.outputs['model_dir'],\n",
    "        load_dataset_task.outputs['labels']\n",
    "    )\n",
    "\n",
    "    convert_model_to_onnx_task = convert_model_to_onnx_comp(\n",
    "        train_model_task.outputs['model_dir']\n",
    "    )\n",
    "\n",
    "    upload_model_task = upload_model_comp(\n",
    "        convert_model_to_onnx_task.outputs['onnx_model_dir'],\n",
    "        minio_url,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    deploy_model_with_kserve_task = deploy_model_with_kserve_comp(\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    deploy_model_with_kserve_task.after(upload_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Run the pipeline within an experiment\n",
    "Create a pipeline run, using the client you initialized in a prior step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/6f189cc3-98f2-4594-bfb2-c9688a1ec5c3\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/cbe390fe-c6af-43fb-a34e-523e4085ad57\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=cbe390fe-c6af-43fb-a34e-523e4085ad57)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See: https://www.kubeflow.org/docs/components/pipelines/overview/caching/#managing-caching-staleness\n",
    "def disable_cache_transformer(op):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\")\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf = PipelineConf()\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n",
    "pipeline_conf.data_passing_method = data_passing_methods.KubernetesVolume(\n",
    "    volume=V1Volume(\n",
    "        name=ARGUMENTS[\"blackboard\"],\n",
    "        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "            \"{{workflow.name}}-%s\" % ARGUMENTS[\"blackboard\"]\n",
    "        ),\n",
    "    ),\n",
    "    path_prefix=f'{ARGUMENTS[\"blackboard\"]}/',\n",
    ")\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    music_genre_classification_pipeline,\n",
    "    arguments=ARGUMENTS,\n",
    "    namespace=NAMESPACE,\n",
    "    pipeline_conf=pipeline_conf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.) Test model deployment\n",
    "See API documentation: https://github.com/kserve/kserve/blob/master/docs/predict-api/v2/required_api.md\n",
    "\n",
    "### 5.1) Check model endpoint availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'music-classification',\n",
       " 'versions': ['1'],\n",
       " 'platform': 'onnxruntime_onnx',\n",
       " 'inputs': [{'name': 'conv2d_input',\n",
       "   'datatype': 'FP32',\n",
       "   'shape': [-1, 64, 173, 1]}],\n",
       " 'outputs': [{'name': 'dense_2', 'datatype': 'FP32', 'shape': [-1, 10]}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOST = MODEL_NAME + \"-predictor-default.\" + NAMESPACE\n",
    "HEADERS = {'Host': HOST}\n",
    "MODEL_ENDPOINT = \"http://\" + MODEL_NAME + \"-predictor-default/v2/models/\" + MODEL_NAME\n",
    "\n",
    "res = requests.get(MODEL_ENDPOINT, headers=HEADERS)\n",
    "response = json.loads(res.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note you can also do this:\n",
    "```curl -H \"Host: $HOST\" $MODEL_ENDPOINT```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Get test audio\n",
    "See: https://commons.wikimedia.org/wiki/Category:Audio_files_of_blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO = \"audio.ogg\"\n",
    "\n",
    "AUDIO_URL = \"https://upload.wikimedia.org/wikipedia/commons/7/7c/Boogie_lead_riff.ogg\"\n",
    "#AUDIO_URL = \"https://upload.wikimedia.org/wikipedia/commons/9/99/Blues_Rock.ogg\"\n",
    "\n",
    "!wget $AUDIO_URL -O $AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(AUDIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Convert test audio to 2-seconds Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050\n",
    "N_FFT = 512\n",
    "HOP_LENGTH = N_FFT // 2\n",
    "N_MELS = 64\n",
    "\n",
    "\n",
    "def convert_to_melspecs(filename):\n",
    "    audios = get_batches(filename)\n",
    "    return batch_log_melspectrogram(audios)\n",
    "\n",
    "\n",
    "def get_batches(audio):\n",
    "    y, sr = lb.load(audio, mono=True)\n",
    "\n",
    "    duration = lb.core.get_duration(y)\n",
    "\n",
    "    audios = []\n",
    "    # prune first 2 seconds and ending (assumption: does not include important data)\n",
    "    for i in range(2, math.floor(duration), 2):\n",
    "        y_sample, sr_sample = lb.load(audio, mono=True, offset=i, duration=2.0)\n",
    "        audios.append(y_sample)\n",
    "\n",
    "    return audios\n",
    "\n",
    "\n",
    "def log_melspectrogram(data):\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y=data,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        n_fft=N_FFT,\n",
    "        n_mels=N_MELS)\n",
    "    return lb.power_to_db(melspec**2)\n",
    "\n",
    "\n",
    "def batch_log_melspectrogram(data_list):\n",
    "    melspecs = np.asarray([\n",
    "        log_melspectrogram(data_list[i]) for i in range(len(data_list)-1)\n",
    "    ])\n",
    "    melspecs = melspecs.reshape(\n",
    "        melspecs.shape[0],\n",
    "        melspecs.shape[1],\n",
    "        melspecs.shape[2],\n",
    "        1\n",
    "    )\n",
    "    return melspecs\n",
    "\n",
    "\n",
    "melspecs = convert_to_melspecs(AUDIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) Visualize a Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = (int)(melspecs.shape[0]/2)\n",
    "example_melspec = melspecs[middle]\n",
    "example_melspec = example_melspec.reshape(example_melspec.shape[0], example_melspec.shape[1])\n",
    "\n",
    "pylab.axis('off')  # no axis\n",
    "pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])  # Remove the white edge\n",
    "display.specshow(example_melspec, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5) Score example Mel Spectromgram against model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(melspec):\n",
    "    PREDICT_ENDPOINT = MODEL_ENDPOINT + \"/infer\"\n",
    "\n",
    "    payload = {\n",
    "      \"inputs\": [{\n",
    "          \"name\": \"conv2d_input\",\n",
    "          \"shape\": [1, 64, 173, 1],\n",
    "          \"datatype\": \"FP32\",\n",
    "          \"data\": melspec.tolist()\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "    res = requests.post(PREDICT_ENDPOINT, headers=HEADERS, data=json.dumps(payload))\n",
    "    response = json.loads(res.text)\n",
    "    return response['outputs'][0]['data']\n",
    "\n",
    "\n",
    "test_score = score(example_melspec)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_LABELS = [\n",
    "    \"Blues\",\n",
    "    \"Classical\",\n",
    "    \"Country\",\n",
    "    \"Disco\",\n",
    "    \"Hip hop\",\n",
    "    \"Jazz\",\n",
    "    \"Metal\",\n",
    "    \"Pop\",\n",
    "    \"Reggae\",\n",
    "    \"Rock\"\n",
    "]\n",
    "\n",
    "GENRE_LABELS[np.argmax(test_score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6) Score each Mel Spectrogram against deployed model & aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = [0.0 for genre in GENRE_LABELS]\n",
    "counts = [0 for genre in GENRE_LABELS]\n",
    "\n",
    "for melspec in melspecs:\n",
    "    predictions = score(melspec)\n",
    "    for i in range(len(GENRE_LABELS)):\n",
    "        probabilities[i] += predictions[i]\n",
    "    counts[np.argmax(predictions)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7) Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(GENRE_LABELS)):\n",
    "    probabilities[i] = probabilities[i]/len(melspecs)\n",
    "    print(GENRE_LABELS[i] + \": \" + str(probabilities[i]) + \" (\" + str(counts[i]) + \"x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
