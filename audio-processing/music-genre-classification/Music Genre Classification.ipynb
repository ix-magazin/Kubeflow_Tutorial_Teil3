{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification\n",
    "\n",
    "Classify the musical genre of a given audio track - from data to deployed model. Adapted from the work of Huang, Serafini, and Pugh [1].\n",
    "\n",
    "## Authors\n",
    "- Sebastian Lehrig <sebastian.lehrig1@ibm.com>\n",
    "- Marvin Giessing <MARVING@de.ibm.com>\n",
    "\n",
    "## License\n",
    "Apache-2.0 License\n",
    "\n",
    "## References\n",
    "[1] original paper: http://cs229.stanford.edu/proj2018/report/21.pdf\n",
    "\n",
    "[2] code: https://github.com/derekahuang/Music-Classification\n",
    "\n",
    "[3] Preprocessed Data: https://drive.google.com/file/d/12mCgkvbmissLh2Vop0bp_t98G8QCaV1E/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.) Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "import json\n",
    "import kfp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "import kfp.dsl as dsl\n",
    "from kfp.dsl import PipelineConf, data_passing_methods\n",
    "from kubernetes.client.models import V1Volume, V1PersistentVolumeClaimVolumeSource\n",
    "import librosa as lb\n",
    "from librosa import display\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab\n",
    "import requests\n",
    "from typing import List, NamedTuple\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-specific configurations\n",
    "#\n",
    "# %env CLUSTER_CONFIGURATION_SECRET remote-power-cluster\n",
    "# %env CLUSTER_CONFIGURATION_SECRET remote-x86-cluster\n",
    "# %env CLUSTER_CONFIGURATION_SECRET remote-x86-telekom-cluster\n",
    "# %env TRAINING_GPUS 1\n",
    "# %env TRAINING_NODE_SELECTOR nvidia.com/gpu.product: \"Tesla-V100-SXM2-32GB\"\n",
    "# %env TRAINING_NODE_SELECTOR kubernetes.io/hostname: node2\n",
    "#\n",
    "# Reset:\n",
    "# del os.environ['CLUSTER_CONFIGURATION_SECRET']\n",
    "# del os.environ['TRAINING_GPUS']\n",
    "# del os.environ['TRAINING_NODE_SELECTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPONENT_CATALOG_FOLDER = f\"{os.getenv('HOME')}/components\"\n",
    "COMPONENT_CATALOG_GIT = \"https://github.com/lehrig/kubeflow-ppc64le-components.git\"\n",
    "COMPONENT_CATALOG_RELEASE = \"main\"\n",
    "\n",
    "LOAD_DATASET_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/data-collection/load-dataset/component.yaml\"\n",
    ")\n",
    "TRAIN_MODEL_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/train-model-job/component.yaml\"\n",
    ")\n",
    "PLOT_CONFUSION_MATRIX_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/plot-confusion-matrix/component.yaml\"\n",
    ")\n",
    "CONVERT_MODEL_TO_ONNX_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/convert-to-onnx/component.yaml\"\n",
    ")\n",
    "UPLOAD_MODEL_COMPONENT = (\n",
    "    f\"{COMPONENT_CATALOG_FOLDER}/model-building/upload-model/component.yaml\"\n",
    ")\n",
    "DEPLOY_MODEL_WITH_KSERVE_COMPONENT = f\"{COMPONENT_CATALOG_FOLDER}/model-deployment/deploy-model-with-kserve/component.yaml\"\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ibm/kubeflow-notebook-image-ppc64le:latest\"\n",
    "\n",
    "ARGUMENTS = {\n",
    "    \"blackboard\": \"artefacts\",\n",
    "    \"dataset_url\": \"Lehrig/GTZAN-Collection\",\n",
    "    \"dataset_configuration\": \"mel_spectrograms\",\n",
    "    \"dataset_label_columns\": [\"genre\"],\n",
    "    \"model_name\": \"music-classification\",\n",
    "    \"cluster_configuration_secret\": os.getenv(\n",
    "        \"CLUSTER_CONFIGURATION_SECRET\", default=\"\"\n",
    "    ),\n",
    "    \"training_gpus\": os.getenv(\"TRAINING_GPUS\", default=\"1\"),\n",
    "    \"training_node_selector\": os.getenv(\"TRAINING_NODE_SELECTOR\", default=\"\"),\n",
    "}\n",
    "MODEL_NAME = ARGUMENTS[\"model_name\"]\n",
    "\n",
    "with open(\"/var/run/secrets/kubernetes.io/serviceaccount/namespace\") as f:\n",
    "    NAMESPACE = f.read()\n",
    "\n",
    "ARGUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Let's start with creating a client object for interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) The main part consists of defining the end-to-end workflow functions and create components from them\n",
    "### 2.0) Load component catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --branch $COMPONENT_CATALOG_RELEASE $COMPONENT_CATALOG_GIT $COMPONENT_CATALOG_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Load dataset (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset_comp = kfp.components.load_component_from_file(LOAD_DATASET_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Preprocess data (one hot encoding etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(\n",
    "    dataset_dir: InputPath(str),\n",
    "    train_dataset_dir: OutputPath(str),\n",
    "    validation_dataset_dir: OutputPath(str),\n",
    "    test_dataset_dir: OutputPath(str),\n",
    "    batch_size: int = 200,\n",
    "):\n",
    "    \"\"\"Split data into train/dev/test data. Saves result into `prep_dataset_dir`.\"\"\"\n",
    "\n",
    "    from datasets import load_from_disk\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from transformers import DefaultDataCollator\n",
    "\n",
    "    print(f\"Loading input dataset from {dataset_dir}...\")\n",
    "    dataset = load_from_disk(dataset_dir)\n",
    "\n",
    "    # Preprocess\n",
    "    num_classes = dataset[\"train\"].features[\"genre\"].num_classes\n",
    "    one_hot_matrix = np.eye(num_classes)\n",
    "\n",
    "    def process(examples):\n",
    "        examples[\"genre\"] = [one_hot_matrix[genre] for genre in examples[\"genre\"]]\n",
    "        return examples\n",
    "\n",
    "    prep_dataset = dataset.map(\n",
    "        process, batched=True, batch_size=batch_size, num_proc=2, keep_in_memory=True\n",
    "    )\n",
    "\n",
    "    def save_as_tfdataset(\n",
    "        dataset, columns, label_columns, data_collator, directory, shuffle\n",
    "    ):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf_dataset = dataset.to_tf_dataset(\n",
    "            columns=columns,\n",
    "            label_cols=label_columns,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=data_collator,\n",
    "        )\n",
    "\n",
    "        print(f\"Saving pre-processed dataset to '{directory}'...\")\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        tf.data.experimental.save(tf_dataset, directory)\n",
    "\n",
    "        print(f\"Pre-processed dataset saved. Contents of '{directory}':\")\n",
    "        print(os.listdir(directory))\n",
    "\n",
    "    # prep_dataset = prep_dataset.with_format(\"numpy\")\n",
    "    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "    columns = [\"mel_spectrogram\"]\n",
    "    label_columns = [\"genre\"]\n",
    "    save_as_tfdataset(\n",
    "        prep_dataset[\"train\"],\n",
    "        columns,\n",
    "        label_columns,\n",
    "        data_collator,\n",
    "        train_dataset_dir,\n",
    "        True,\n",
    "    )\n",
    "    save_as_tfdataset(\n",
    "        prep_dataset[\"validation\"],\n",
    "        columns,\n",
    "        label_columns,\n",
    "        data_collator,\n",
    "        validation_dataset_dir,\n",
    "        False,\n",
    "    )\n",
    "    save_as_tfdataset(\n",
    "        prep_dataset[\"test\"],\n",
    "        columns,\n",
    "        label_columns,\n",
    "        data_collator,\n",
    "        test_dataset_dir,\n",
    "        False,\n",
    "    )\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "\n",
    "preprocess_dataset_comp = kfp.components.create_component_from_func(\n",
    "    func=preprocess_dataset, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_dataset_dir: InputPath(str),\n",
    "    validation_dataset_dir: InputPath(str),\n",
    "    model_dir: OutputPath(str),\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 200,\n",
    "):\n",
    "    \"\"\"Trains CNN model. Once trained, the model is persisted to `model_dir`.\"\"\"\n",
    "\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.callbacks import (\n",
    "        EarlyStopping,\n",
    "        ModelCheckpoint,\n",
    "        ReduceLROnPlateau,\n",
    "        TensorBoard,\n",
    "    )\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import (\n",
    "        BatchNormalization,\n",
    "        Conv2D,\n",
    "        Dense,\n",
    "        Dropout,\n",
    "        Flatten,\n",
    "        MaxPooling2D,\n",
    "    )\n",
    "    from tensorflow.keras import regularizers\n",
    "    import time\n",
    "\n",
    "    def load_datasets():\n",
    "        train_dataset = tf.data.experimental.load(train_dataset_dir)\n",
    "        validation_dataset = tf.data.experimental.load(validation_dataset_dir)\n",
    "        return (train_dataset, validation_dataset)\n",
    "\n",
    "    def build_model():\n",
    "        model = Sequential()\n",
    "\n",
    "        # Feature Learning Layers\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                64,\n",
    "                kernel_size=(4, 4),\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=regularizers.l2(0.04),\n",
    "                input_shape=(64, 173, 1),\n",
    "            )\n",
    "        )\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 4)))\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                64, (3, 5), activation=\"relu\", kernel_regularizer=regularizers.l2(0.04)\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                64, (2, 2), activation=\"relu\", kernel_regularizer=regularizers.l2(0.04)\n",
    "            )\n",
    "        )\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # Classification Layers\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.04))\n",
    "        )\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(\n",
    "            Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.04))\n",
    "        )\n",
    "        model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "        return model\n",
    "\n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset, validation_dataset = load_datasets()\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    model = build_model()\n",
    "    print(model.summary())\n",
    "\n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"categorical_accuracy\"],\n",
    "    )\n",
    "\n",
    "    print(\"Initiallizing training callbacks...\")\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=20, verbose=0, mode=\"min\"),\n",
    "        ModelCheckpoint(\n",
    "            f\"{model_dir}/best_model.keras\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=7,\n",
    "            verbose=1,\n",
    "            min_delta=0.0001,\n",
    "            mode=\"min\",\n",
    "        ),\n",
    "        TensorBoard(log_dir=\"./logs\", histogram_freq=1),\n",
    "    ]\n",
    "    # TODO\n",
    "    # Connect TensorBoard to s3://minio-service-kubeflow.apps.b2s001.pbm.ihost.com/mlpipeline/tensorboard\n",
    "    # Will need tensorflow-io[tensorflow] package for that\n",
    "    # See: https://github.com/tensorflow/tensorflow/issues/40302#issuecomment-918917472\n",
    "\n",
    "    print(\"Starting model training...\")\n",
    "    start = time.time()\n",
    "    hist = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    print(\"\\n\\nTraining took \", time.time() - start, \"seconds\")\n",
    "\n",
    "    print(\"Model train history:\")\n",
    "    print(hist.history)\n",
    "\n",
    "    print(f\"Saving model to: {model_dir}\")\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model.save(model_dir)\n",
    "    print(f\"Model saved to: {model_dir}\")\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "\n",
    "train_specification = kfp.components.func_to_component_text(func=train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_comp = kfp.components.load_component_from_file(TRAIN_MODEL_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Evaluate model with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    test_dataset_dir: InputPath(str), model_dir: InputPath(str), batch_size: int = 20\n",
    ") -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]):\n",
    "    \"\"\"Loads a saved model from file and uses a pre-downloaded dataset for evaluation.\n",
    "    Model metrics are persisted to `{metrics_path}` for Kubeflow Pipelines metadata.\"\"\"\n",
    "\n",
    "    from collections import namedtuple\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "\n",
    "    test_dataset = tf.data.experimental.load(test_dataset_dir)\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    (loss, accuracy) = model.evaluate(test_dataset)\n",
    "\n",
    "    print((loss, accuracy))\n",
    "\n",
    "    metrics = {\n",
    "        \"metrics\": [\n",
    "            {\"name\": \"loss\", \"numberValue\": str(loss), \"format\": \"PERCENTAGE\"},\n",
    "            {\"name\": \"accuracy\", \"numberValue\": str(accuracy), \"format\": \"PERCENTAGE\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "\n",
    "    return out_tuple(json.dumps(metrics))\n",
    "\n",
    "\n",
    "evaluate_model_comp = kfp.components.create_component_from_func(\n",
    "    func=evaluate_model, base_image=BASE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Create confusion matrix (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_comp = kfp.components.load_component_from_file(\n",
    "    PLOT_CONFUSION_MATRIX_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6) Convert model to ONNX (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_model_to_onnx_comp = kfp.components.load_component_from_file(\n",
    "    CONVERT_MODEL_TO_ONNX_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7) Upload model to MinIO artifact store (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_model_comp = kfp.components.load_component_from_file(UPLOAD_MODEL_COMPONENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8) Deploy the model using KServe (by reusing a Kubeflow component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_model_with_kserve_comp = kfp.components.load_component_from_file(\n",
    "    DEPLOY_MODEL_WITH_KSERVE_COMPONENT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Create the actual pipeline by combining the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Music Genre Classification\",\n",
    "    description=\"An example pipeline that performs a music genre classification on audio data\",\n",
    ")\n",
    "def music_genre_classification_pipeline(\n",
    "    blackboard: str,\n",
    "    dataset_url: str,\n",
    "    dataset_configuration: str,\n",
    "    dataset_label_columns: List[str],\n",
    "    model_name: str,\n",
    "    cluster_configuration_secret: str,\n",
    "    training_gpus: int,\n",
    "    training_node_selector: str,\n",
    "):\n",
    "    create_blackboard = dsl.VolumeOp(\n",
    "        name=\"Create Artefacts Blackboard\",\n",
    "        resource_name=blackboard,\n",
    "        modes=dsl.VOLUME_MODE_RWO,\n",
    "        size=\"4Gi\",\n",
    "        set_owner_reference=True,\n",
    "    )\n",
    "\n",
    "    load_dataset_task = load_dataset_comp(\n",
    "        path=dataset_url,\n",
    "        configuration=dataset_configuration,\n",
    "        label_columns=dataset_label_columns,\n",
    "    )\n",
    "    load_dataset_task.after(create_blackboard)\n",
    "\n",
    "    preprocess_dataset_task = preprocess_dataset_comp(\n",
    "        dataset_dir=load_dataset_task.outputs[\"dataset_dir\"],\n",
    "    )\n",
    "\n",
    "    # InputPath and OutputPath like \"prep_dataset_dir\" & \"model_dir\":\n",
    "    # Use name of parameters of train component on right-hand side.\n",
    "    train_parameters = {\n",
    "        \"train_dataset_dir\": \"train_dataset_dir\",\n",
    "        \"validation_dataset_dir\": \"validation_dataset_dir\",\n",
    "        \"model_dir\": \"model_dir\",\n",
    "    }\n",
    "\n",
    "    train_model_task = train_model_comp(\n",
    "        preprocess_dataset_task.outputs[\"train_dataset_dir\"],\n",
    "        preprocess_dataset_task.outputs[\"validation_dataset_dir\"],\n",
    "        train_specification,\n",
    "        train_parameters,\n",
    "        model_name=model_name,\n",
    "        gpus=training_gpus,\n",
    "        node_selector=training_node_selector,\n",
    "        cluster_configuration_secret=cluster_configuration_secret,\n",
    "    )\n",
    "\n",
    "    evaluate_model_comp(\n",
    "        preprocess_dataset_task.outputs[\"test_dataset_dir\"],\n",
    "        train_model_task.outputs[\"model_dir\"],\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix_comp(\n",
    "        input_columns=[\"mel_spectrogram\"],\n",
    "        label_columns=load_dataset_task.outputs[\"labels\"],\n",
    "        test_dataset_dir=preprocess_dataset_task.outputs[\"test_dataset_dir\"],\n",
    "        model_dir=train_model_task.outputs[\"model_dir\"],\n",
    "    )\n",
    "\n",
    "    convert_model_to_onnx_task = convert_model_to_onnx_comp(\n",
    "        train_model_task.outputs[\"model_dir\"]\n",
    "    )\n",
    "\n",
    "    upload_model_task = upload_model_comp(\n",
    "        convert_model_to_onnx_task.outputs[\"onnx_model_dir\"], model_name=model_name\n",
    "    )\n",
    "\n",
    "    deploy_model_with_kserve_task = deploy_model_with_kserve_comp(model_name=model_name)\n",
    "\n",
    "    deploy_model_with_kserve_task.after(upload_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Run the pipeline within an experiment\n",
    "Create a pipeline run, using the client you initialized in a prior step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://www.kubeflow.org/docs/components/pipelines/overview/caching/#managing-caching-staleness\n",
    "def disable_cache_transformer(op):\n",
    "    if isinstance(op, dsl.ContainerOp):\n",
    "        op.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    else:\n",
    "        op.add_pod_annotation(\n",
    "            name=\"pipelines.kubeflow.org/max_cache_staleness\", value=\"P0D\"\n",
    "        )\n",
    "    return op\n",
    "\n",
    "\n",
    "pipeline_conf = PipelineConf()\n",
    "pipeline_conf.add_op_transformer(disable_cache_transformer)\n",
    "pipeline_conf.data_passing_method = data_passing_methods.KubernetesVolume(\n",
    "    volume=V1Volume(\n",
    "        name=ARGUMENTS[\"blackboard\"],\n",
    "        persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(\n",
    "            \"{{workflow.name}}-%s\" % ARGUMENTS[\"blackboard\"]\n",
    "        ),\n",
    "    ),\n",
    "    path_prefix=f'{ARGUMENTS[\"blackboard\"]}/',\n",
    ")\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    music_genre_classification_pipeline,\n",
    "    arguments=ARGUMENTS,\n",
    "    namespace=NAMESPACE,\n",
    "    pipeline_conf=pipeline_conf,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.) Test model deployment\n",
    "See API documentation: https://github.com/kserve/kserve/blob/master/docs/predict-api/v2/required_api.md\n",
    "\n",
    "### 5.1) Check model endpoint availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = MODEL_NAME + \"-predictor-default.\" + NAMESPACE\n",
    "HEADERS = {'Host': HOST}\n",
    "MODEL_ENDPOINT = \"http://\" + MODEL_NAME + \"-predictor-default/v2/models/\" + MODEL_NAME\n",
    "\n",
    "res = requests.get(MODEL_ENDPOINT, headers=HEADERS)\n",
    "response = json.loads(res.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note you can also do this:\n",
    "```curl -H \"Host: $HOST\" $MODEL_ENDPOINT```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Get test audio\n",
    "See: https://commons.wikimedia.org/wiki/Category:Audio_files_of_blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO = \"audio.ogg\"\n",
    "\n",
    "AUDIO_URL = \"https://upload.wikimedia.org/wikipedia/commons/7/7c/Boogie_lead_riff.ogg\"\n",
    "# AUDIO_URL = \"https://upload.wikimedia.org/wikipedia/commons/9/99/Blues_Rock.ogg\"\n",
    "\n",
    "!wget $AUDIO_URL -O $AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(AUDIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Convert test audio to 2-seconds Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050\n",
    "N_FFT = 512\n",
    "HOP_LENGTH = N_FFT // 2\n",
    "N_MELS = 64\n",
    "\n",
    "\n",
    "def convert_to_melspecs(filename):\n",
    "    audios = get_batches(filename)\n",
    "    return batch_log_melspectrogram(audios)\n",
    "\n",
    "\n",
    "def get_batches(audio):\n",
    "    y, sr = lb.load(audio, mono=True)\n",
    "\n",
    "    duration = lb.core.get_duration(y)\n",
    "\n",
    "    audios = []\n",
    "    # prune first 2 seconds and ending (assumption: does not include important data)\n",
    "    for i in range(2, math.floor(duration), 2):\n",
    "        y_sample, sr_sample = lb.load(audio, mono=True, offset=i, duration=2.0)\n",
    "        audios.append(y_sample)\n",
    "\n",
    "    return audios\n",
    "\n",
    "\n",
    "def log_melspectrogram(data):\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y=data, hop_length=HOP_LENGTH, n_fft=N_FFT, n_mels=N_MELS\n",
    "    )\n",
    "    return lb.power_to_db(melspec**2)\n",
    "\n",
    "\n",
    "def batch_log_melspectrogram(data_list):\n",
    "    melspecs = np.asarray(\n",
    "        [log_melspectrogram(data_list[i]) for i in range(len(data_list) - 1)]\n",
    "    )\n",
    "    melspecs = melspecs.reshape(\n",
    "        melspecs.shape[0], melspecs.shape[1], melspecs.shape[2], 1\n",
    "    )\n",
    "    return melspecs\n",
    "\n",
    "\n",
    "melspecs = convert_to_melspecs(AUDIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) Visualize a Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = (int)(melspecs.shape[0] / 2)\n",
    "example_melspec = melspecs[middle]\n",
    "example_melspec = example_melspec.reshape(\n",
    "    example_melspec.shape[0], example_melspec.shape[1]\n",
    ")\n",
    "\n",
    "pylab.axis(\"off\")  # no axis\n",
    "pylab.axes(\n",
    "    [0.0, 0.0, 1.0, 1.0], frameon=False, xticks=[], yticks=[]\n",
    ")  # Remove the white edge\n",
    "display.specshow(example_melspec, y_axis=\"mel\", x_axis=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5) Score example Mel Spectrogram against model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(melspec):\n",
    "    PREDICT_ENDPOINT = MODEL_ENDPOINT + \"/infer\"\n",
    "\n",
    "    payload = {\n",
    "      \"inputs\": [{\n",
    "          \"name\": \"conv2d_input\",\n",
    "          \"shape\": [1, 64, 173, 1],\n",
    "          \"datatype\": \"FP32\",\n",
    "          \"data\": melspec.tolist()\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "    res = requests.post(PREDICT_ENDPOINT, headers=HEADERS, data=json.dumps(payload))\n",
    "    response = json.loads(res.text)\n",
    "    return response['outputs'][0]['data']\n",
    "\n",
    "\n",
    "test_score = score(example_melspec)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_LABELS = [\n",
    "    \"Blues\",\n",
    "    \"Classical\",\n",
    "    \"Country\",\n",
    "    \"Disco\",\n",
    "    \"Hip hop\",\n",
    "    \"Jazz\",\n",
    "    \"Metal\",\n",
    "    \"Pop\",\n",
    "    \"Reggae\",\n",
    "    \"Rock\"\n",
    "]\n",
    "\n",
    "GENRE_LABELS[np.argmax(test_score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6) Score each Mel Spectrogram against deployed model & aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = [0.0 for genre in GENRE_LABELS]\n",
    "counts = [0 for genre in GENRE_LABELS]\n",
    "\n",
    "for melspec in melspecs:\n",
    "    predictions = score(melspec)\n",
    "    for i in range(len(GENRE_LABELS)):\n",
    "        probabilities[i] += predictions[i]\n",
    "    counts[np.argmax(predictions)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7) Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(GENRE_LABELS)):\n",
    "    probabilities[i] = probabilities[i]/len(melspecs)\n",
    "    print(GENRE_LABELS[i] + \": \" + str(probabilities[i]) + \" (\" + str(counts[i]) + \"x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
