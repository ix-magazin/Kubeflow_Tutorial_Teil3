# Modell-Training für Fortgeschrittene in Kubeflow
Code des Beispiels aus dem dritten Teil des Kubeflow-Tutorials von Sebastian Lehrig, erschienen in [Ausgabe 10/2023](https://www.heise.de/select/ix/2023/10/2315908013020269099) des [iX-Magazins](https://www.heise.de/select/ix/2023/10).

# iX-tract
- Beim Umgang mit komplexen Daten und Modellen mit Milliarden von Parametern setzen Data Scientists auf Transfer-Lernen und das Finetuning von bereits vorhandenen Modellen.
- Zum Beschleunigen des Trainings lassen sich TPUs und GPUs auch in der Cloud nutzen, wenn man keine Spezialhardware vorhalten möchte. Hierbei helfen Techniken für das Training auf verteilten Maschinen.
- Um beim Train-Bursting in der Cloud nicht den Überblick zu verlieren, hilft TensorBoard dabei, die wichtigsten Metriken wie Accuracy, Loss und Learning Rate im Auge zu behalten.
- Mit den AutoML-Werkzeugen von Kubeflow lassen sich die wichtigsten Hyperparameter finden, mit denen sich die Performance der Modelle optimieren lässt.
