{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bb82671-7f27-44bb-bad6-1e1dd2cfb9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "\n",
    "from kubeflow.katib import ApiClient\n",
    "from kubeflow.katib import V1beta1ExperimentSpec\n",
    "from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "from kubeflow.katib import V1beta1ParameterSpec\n",
    "from kubeflow.katib import V1beta1FeasibleSpace\n",
    "from kubeflow.katib import V1beta1TrialTemplate\n",
    "from kubeflow.katib import V1beta1TrialParameterSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c413b-06af-4c2e-9830-fcb336dee843",
   "metadata": {},
   "source": [
    "## 1. Katib hyperparameter tuning task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a22b42-e54c-4eb6-9d1a-0f1481c3ee4c",
   "metadata": {},
   "source": [
    "Here are the different steps to create a Katib experiment for tuning hyperparameters. \\\n",
    "First of all, you have to specify an objective whose type is either \"minimize\" or \"maximize\". It takes an metric and a goal to reach. \\\n",
    "\\\n",
    "Then you have to specify a search algorithm. Katib supports a lot of various AutoML algorithms, such as Bayesian optimization, Tree of Parzen Estimators, Random Search, Covariance Matrix Adaptation Evolution Strategy, Hyperband, Efficient Neural Architecture Search, Differentiable Architecture Search and many more. \\\n",
    "\\\n",
    "Then, you have to choose the parameters specs, specifying the name, type and more importantly the search space. \\\n",
    "\\\n",
    "After that, a trial template is defined as a worker job. The worker job is the process that runs to evaluate a trial and calculate its objective value. Many types of job are supported: Job, TFJob, PyTorchJob, MXJob, XGBoost for example. The template loads your model that is stored inside an image and runs it with the different sets of parameters. \\\n",
    "\\\n",
    "When all these steps are completed, you can finally create a Katib experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3407a371-befe-4f87-950e-e1fc1e45456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should define the Experiment name, namespace and number of training steps in the arguments.\n",
    "def create_katib_experiment_task(experiment_name, experiment_namespace, training_steps):\n",
    "    # Trial count specification.\n",
    "    max_trial_count = 5\n",
    "    max_failed_trial_count = 3\n",
    "    parallel_trial_count = 2\n",
    "\n",
    "    # Objective specification.\n",
    "    objective = V1beta1ObjectiveSpec(\n",
    "        type=\"minimize\",\n",
    "        goal=0.001,\n",
    "        objective_metric_name=\"loss\"\n",
    "    )\n",
    "\n",
    "    # Algorithm specification.\n",
    "    algorithm = V1beta1AlgorithmSpec(\n",
    "        algorithm_name=\"random\",\n",
    "    )\n",
    "\n",
    "    # Experiment search space.\n",
    "    # In this example we tune learning rate and batch size.\n",
    "    # These are not proper parameters but the parameters specifications.\n",
    "    parameters = [\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"learning_rate\",\n",
    "            parameter_type=\"double\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                min=\"0.01\",\n",
    "                max=\"0.05\"\n",
    "            ),\n",
    "        ),\n",
    "        V1beta1ParameterSpec(\n",
    "            name=\"batch_size\",\n",
    "            parameter_type=\"int\",\n",
    "            feasible_space=V1beta1FeasibleSpace(\n",
    "                # min=\"80\",\n",
    "                # max=\"100\"\n",
    "                min=2,\n",
    "                max=4\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Experiment Trial template.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    trial_spec = {\n",
    "        \"apiVersion\": \"kubeflow.org/v1\",\n",
    "        \"kind\": \"TFJob\",\n",
    "        \"spec\": {\n",
    "            \"tfReplicaSpecs\": {\n",
    "                \"Chief\": {\n",
    "                    \"replicas\": 1,\n",
    "                    \"restartPolicy\": \"OnFailure\",\n",
    "                    \"template\": {\n",
    "                        \"metadata\": {\n",
    "                            \"annotations\": {\n",
    "                                \"sidecar.istio.io/inject\": \"false\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": \"tensorflow\",\n",
    "                                    \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist:ppc64le\",\n",
    "                                    \"command\": [\n",
    "                                        \"python\",\n",
    "                                        \"/opt/model.py\",\n",
    "                                        \"--tf-train-steps=\" + str(training_steps),\n",
    "                                        \"--tf-learning-rate=${trialParameters.learningRate}\",\n",
    "                                        \"--tf-batch-size=${trialParameters.batchSize}\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"Worker\": {\n",
    "                    \"replicas\": 1,\n",
    "                    \"restartPolicy\": \"OnFailure\",\n",
    "                    \"template\": {\n",
    "                        \"metadata\": {\n",
    "                            \"annotations\": {\n",
    "                                \"sidecar.istio.io/inject\": \"false\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": \"tensorflow\",\n",
    "                                    \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist:ppc64le\",\n",
    "                                    \"command\": [\n",
    "                                        \"python\",\n",
    "                                        \"/opt/model.py\",\n",
    "                                        \"--tf-train-steps=\" + str(training_steps),\n",
    "                                        \"--tf-learning-rate=${trialParameters.learningRate}\",\n",
    "                                        \"--tf-batch-size=${trialParameters.batchSize}\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Configure parameters for the Trial template.\n",
    "    # This template is a wrapper object for the template defined above. It takes as parameters a name, the actual parameters and the parameter specs.\n",
    "    trial_template = V1beta1TrialTemplate(\n",
    "        primary_container_name=\"tensorflow\",\n",
    "        trial_parameters=[\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"learningRate\",\n",
    "                description=\"Learning rate for the training model\",\n",
    "                reference=\"learning_rate\"\n",
    "            ),\n",
    "            V1beta1TrialParameterSpec(\n",
    "                name=\"batchSize\",\n",
    "                description=\"Batch size for the model\",\n",
    "                reference=\"batch_size\"\n",
    "            ),\n",
    "        ],\n",
    "        trial_spec=trial_spec\n",
    "    )\n",
    "\n",
    "    # Create an Experiment from the above parameters.\n",
    "    experiment_spec = V1beta1ExperimentSpec(\n",
    "        max_trial_count=max_trial_count,\n",
    "        max_failed_trial_count=max_failed_trial_count,\n",
    "        parallel_trial_count=parallel_trial_count,\n",
    "        objective=objective,\n",
    "        algorithm=algorithm,\n",
    "        parameters=parameters,\n",
    "        trial_template=trial_template\n",
    "    )\n",
    "\n",
    "    # Create the KFP task for the Katib Experiment.\n",
    "    # Experiment Spec should be serialized to a valid Kubernetes object.\n",
    "    # katib_experiment_launcher_op = components.load_component_from_url(\n",
    "    #     \"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/katib-launcher/component.yaml\")\n",
    "    katib_experiment_launcher_op = components.load_component_from_file(\"katib-pipelines-launcher.yaml\")\n",
    "    op = katib_experiment_launcher_op(\n",
    "        experiment_name=experiment_name,\n",
    "        experiment_namespace=experiment_namespace,\n",
    "        experiment_spec=ApiClient().sanitize_for_serialization(experiment_spec),\n",
    "        experiment_timeout_minutes=60,\n",
    "        delete_finished_experiment=False)\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63af7e4-5935-445f-a3ab-ba1ad78abe5f",
   "metadata": {},
   "source": [
    "## 2. TFJob training task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72c10041-1526-4c41-9534-f588d5b6be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts Katib Experiment HP results to args.\n",
    "def convert_katib_results(katib_results) -> str:\n",
    "    import json\n",
    "    import pprint\n",
    "    katib_results_json = json.loads(katib_results)\n",
    "    print(\"Katib results:\")\n",
    "    pprint.pprint(katib_results_json)\n",
    "    best_hps = []\n",
    "    for pa in katib_results_json[\"currentOptimalTrial\"][\"parameterAssignments\"]:\n",
    "        if pa[\"name\"] == \"learning_rate\":\n",
    "            best_hps.append(\"--tf-learning-rate=\" + pa[\"value\"])\n",
    "        elif pa[\"name\"] == \"batch_size\":\n",
    "            best_hps.append(\"--tf-batch-size=\" + pa[\"value\"])\n",
    "    print(\"Best Hyperparameters: {}\".format(best_hps))\n",
    "    return \" \".join(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6916a45a-984a-4d99-a6d0-574d3b7d9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should define the TFJob name, namespace, number of training steps, output of Katib and model volume tasks in the arguments.\n",
    "def create_tfjob_task(tfjob_name, tfjob_namespace, training_steps, katib_op, model_volume_op):\n",
    "    import json\n",
    "    # Get parameters from the Katib Experiment.\n",
    "    # Parameters are in the format \"--tf-learning-rate=0.01 --tf-batch-size=100\"\n",
    "    convert_katib_results_op = components.func_to_container_op(convert_katib_results)\n",
    "    best_hp_op = convert_katib_results_op(katib_op.output)\n",
    "    best_hps = str(best_hp_op.output)\n",
    "\n",
    "    # Create the TFJob Chief and Worker specification with the best Hyperparameters.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    tfjob_chief_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist:ppc64le\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\"\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                            \"python /opt/model.py --tf-export-dir=/mnt/export --tf-train-steps={} {}\".format(training_steps, best_hps)\n",
    "                        ],\n",
    "                        \"volumeMounts\": [\n",
    "                            {\n",
    "                                \"mountPath\": \"/tmp/export\",\n",
    "                                \"name\": \"model-volume\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": [\n",
    "                    {\n",
    "                        \"name\": \"model-volume\",\n",
    "                        \"persistentVolumeClaim\": {\n",
    "                            \"claimName\": str(model_volume_op.outputs[\"name\"])\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    tfjob_worker_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/liuhougangxa/tf-estimator-mnist:ppc64le\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\",\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                          \"python /opt/model.py --tf-export-dir=/mnt/export --tf-train-steps={} {}\".format(training_steps, best_hps) \n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create the KFP task for the TFJob.\n",
    "    # tfjob_launcher_op = components.load_component_from_url(\n",
    "    #     \"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/launcher/component.yaml\")\n",
    "    tfjob_launcher_op = components.load_component_from_file(\"launch-tfjob.yaml\")\n",
    "    op = tfjob_launcher_op(\n",
    "        name=tfjob_name,\n",
    "        namespace=tfjob_namespace,\n",
    "        chief_spec=json.dumps(tfjob_chief_spec),\n",
    "        worker_spec=json.dumps(tfjob_worker_spec),\n",
    "        tfjob_timeout_minutes=60,\n",
    "        delete_finished_tfjob=False)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca347c7-b8bb-46aa-98a5-b3f6bb5bff4e",
   "metadata": {},
   "source": [
    "## 3. KServe inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2f0cd-05b3-4726-980f-104e0b0381ea",
   "metadata": {},
   "source": [
    "TODO: Create a KServe component that works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c3a621dd-2b4d-4b39-b082-ee54b5b34c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_serving_task(model_name, model_namespace, tfjob_op, model_volume_op):\n",
    "\n",
    "#     import os\n",
    "#     api_version = 'serving.kserve.io/v1beta1'\n",
    "#     # serving_component_url = 'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kserve/component.yaml'\n",
    "\n",
    "#     # Uncomment the following two lines if you are using KFServing v0.6.x or v0.5.x\n",
    "#     # api_version = 'serving.kubeflow.org/v1beta1'\n",
    "#     # serving_component_url = 'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/kfserving/component.yaml'\n",
    "    \n",
    "#     os.makedirs(\"/tmp/export/model\", exist_ok=True)\n",
    "\n",
    "    # inference_service = '''\n",
    "    # apiVersion: \"{}\"\n",
    "    # kind: \"InferenceService\"\n",
    "    # metadata:\n",
    "    #   name: {}\n",
    "    #   namespace: {}\n",
    "    #   annotations:\n",
    "    #     \"sidecar.istio.io/inject\": \"false\"\n",
    "    # spec:\n",
    "    #   predictor:\n",
    "    #     tensorflow:\n",
    "    #       storageUri: \"pvc://{}/\"\n",
    "    # '''.format(api_version, model_name, model_namespace, str(model_volume_op.outputs[\"name\"]) + \"model\")\n",
    "\n",
    "#     # serving_launcher_op = components.load_component_from_url(serving_component_url)\n",
    "#     serving_launcher_op = components.load_component_from_file(\"kserve-inference.yaml\")\n",
    "#     serving_launcher_op(action=\"apply\", inferenceservice_yaml=inference_service).add_pvolumes({\"/tmp/export\": model_volume_op.volume}).after(tfjob_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4f579be-cf17-4dff-bcad-961cc461c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy_kserve_component = components.load_component_from_file(\"deploy-kserve.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538f6cb-9166-4468-8553-c65e02b4d197",
   "metadata": {},
   "source": [
    "## Run the kubeflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c52a279-9fcb-41ca-98e5-b5c71d2d46f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/a71794dc-9ce4-4fd8-99c1-88db7720fdf6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/e5c998d4-569b-48dc-9d10-ecf63328fe95\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID:  e5c998d4-569b-48dc-9d10-ecf63328fe95\n"
     ]
    }
   ],
   "source": [
    "name=\"mnist-e2e\"\n",
    "namespace=\"jeremie-chheang-ibm-com\"\n",
    "# training_steps=\"200\"\n",
    "training_steps=\"20\"\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"End to End Pipeline\",\n",
    "    description=\"An end to end mnist example including hyperparameter tuning, train and inference\"\n",
    ")\n",
    "def mnist_pipeline(name=name, namespace=namespace, training_steps=training_steps):\n",
    "    # Run the hyperparameter tuning with Katib.\n",
    "    katib_op = create_katib_experiment_task(name, namespace, training_steps)\n",
    "\n",
    "    # Create volume to train and serve the model.\n",
    "    # model_volume_op = dsl.VolumeOp(\n",
    "    #     name=\"model-volume1\",\n",
    "    #     resource_name=\"model-volume1\",\n",
    "    #     size=\"1Gi\",\n",
    "    #     modes=dsl.VOLUME_MODE_RWO\n",
    "    # )\n",
    "    model_volume_op = dsl.VolumeOp(\n",
    "        name=\"model-volume1\",\n",
    "        resource_name=\"models-volume1\",\n",
    "        modes=dsl.VOLUME_MODE_RWO,\n",
    "        size=\"1Gi\",\n",
    "        generate_unique_name=False,\n",
    "        action='apply'\n",
    "    )\n",
    "\n",
    "    # Run the distributive training with TFJob.\n",
    "    tfjob_op = create_tfjob_task(name, namespace, training_steps, katib_op, model_volume_op)\n",
    "\n",
    "    # Create the KServe inference.\n",
    "    # create_serving_task(name, namespace, tfjob_op, model_volume_op)\n",
    "    deploy_kserve_task = deploy_kserve_component(model_name=\"mnist-e2e\").add_pvolumes({\"/tmp/export\": model_volume_op.volume}).after(tfjob_op)\n",
    "# Run the Kubeflow Pipeline in the user's namespace.\n",
    "\n",
    "kfp_client=kfp.Client()\n",
    "run_id = kfp_client.create_run_from_pipeline_func(mnist_pipeline, namespace=namespace, arguments={}).run_id\n",
    "print(\"Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a72ac-6ec8-4e8d-9b9d-d8f79ef571ff",
   "metadata": {},
   "source": [
    "## Predict from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03248264-7c30-4cad-a699-4d691f011148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Pipeline Run should be succeeded.\n",
    "kfp_run = kfp_client.get_run(run_id=run_id)\n",
    "if kfp_run.run.status == \"Succeeded\":\n",
    "    print(\"Run {} has been Succeeded\\n\".format(run_id))\n",
    "\n",
    "    # Specify the image URL here.\n",
    "    image_url = \"https://raw.githubusercontent.com/kubeflow/katib/master/examples/v1beta1/kubeflow-pipelines/images/9.bmp\"\n",
    "    image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "    data = np.array(image.convert('L').resize((28, 28))).astype(np.float).reshape(-1, 28, 28, 1)\n",
    "    data_formatted = np.array2string(data, separator=\",\", formatter={\"float\": lambda x: \"%.1f\" % x})\n",
    "    json_request = '{{ \"instances\" : {} }}'.format(data_formatted)\n",
    "\n",
    "    # Specify the prediction URL. If you are runing this notebook outside of Kubernetes cluster, you should set the Cluster IP.\n",
    "    url = \"http://{}-predictor-default.{}.svc.cluster.local/v1/models/{}:predict\".format(name, namespace, name)\n",
    "    response = requests.post(url, data=json_request)\n",
    "\n",
    "    print(\"Prediction for the image\")\n",
    "    display(image)\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635effd-48c6-426f-b301-324d64813fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
