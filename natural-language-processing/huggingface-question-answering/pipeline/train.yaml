name: Train
inputs:
- {name: preprocess_dir, type: String}
outputs:
- {name: model, type: String}
- {name: checkpoint_dir, type: String}
implementation:
  container:
    image: quay.io/jeremie_ch/transformers-component:gpu
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def train(preprocess_dir,
                # model_dir: comp.OutputPath(str),
                model_path,
                checkpoint_dir):

          import os
          from datasets import load_from_disk
          import pickle
          from transformers import AutoTokenizer, DefaultDataCollator, \
              AutoModelForQuestionAnswering, TrainingArguments, Trainer

          tokenized_squad = load_from_disk(preprocess_dir)

          data_collator = DefaultDataCollator()

          tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

          model = AutoModelForQuestionAnswering.from_pretrained("distilbert-base-uncased")

          if not os.path.exists(checkpoint_dir):
              os.makedirs(checkpoint_dir)

          training_args = TrainingArguments(
              output_dir=checkpoint_dir,
              evaluation_strategy="epoch",
              learning_rate=2e-5,
              per_device_train_batch_size=16,
              per_device_eval_batch_size=16,
              num_train_epochs=1, #3,
              weight_decay=0.01,
          )

          trainer = Trainer(
              model=model,
              args=training_args,
              # train_dataset=tokenized_squad["train"],
              train_dataset=tokenized_squad["train"].select(range(1000)),
              eval_dataset=tokenized_squad["validation"],
              tokenizer=tokenizer,
              data_collator=data_collator,
          )

          trainer.train()

          model_dir = os.path.dirname(model_path)
          if not os.path.exists(model_dir):
              os.makedirs(model_dir)

          trainer.save_model(model_dir)

      import argparse
      _parser = argparse.ArgumentParser(prog='Train', description='')
      _parser.add_argument("--preprocess-dir", dest="preprocess_dir", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--checkpoint-dir", dest="checkpoint_dir", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = train(**_parsed_args)
    args:
    - --preprocess-dir
    - {inputPath: preprocess_dir}
    - --model
    - {outputPath: model}
    - --checkpoint-dir
    - {outputPath: checkpoint_dir}
